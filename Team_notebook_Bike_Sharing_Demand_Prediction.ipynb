{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Team notebook - Bike Sharing Demand Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vb2ZGCH-byp_",
        "jZJPw5m19_cH",
        "RijbxD1-q6Yg",
        "a51gjUsD3_4f",
        "B2FVQbP6CEbU",
        "TE6kgDO1S-1t",
        "6RgCuU76UKsV",
        "Ih9ZzuHBdkAS",
        "4ewhutXwbTNJ",
        "TmLrVQtjccCS",
        "dD50kmcIAmhX",
        "YSUGn1v7uhaW"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datascience-vivek/Bike-shearing-Demand/blob/main/Team_notebook_Bike_Sharing_Demand_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOGC-qoyhJeX"
      },
      "source": [
        "# <b><u> Project Title : Seoul Bike Sharing Demand Prediction </u></b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y06xIdG26kRF"
      },
      "source": [
        "## <b> Problem Description </b>\n",
        "\n",
        "### Currently Rental bikes are introduced in many urban cities for the enhancement of mobility comfort. It is important to make the rental bike available and accessible to the public at the right time as it lessens the waiting time. Eventually, providing the city with a stable supply of rental bikes becomes a major concern. The crucial part is the prediction of bike count required at each hour for the stable supply of rental bikes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlLxAtlziMbP"
      },
      "source": [
        "## <b> Data Description </b>\n",
        "\n",
        "### <b> The dataset contains weather information (Temperature, Humidity, Windspeed, Visibility, Dewpoint, Solar radiation, Snowfall, Rainfall), the number of bikes rented per hour and date information.</b>\n",
        "\n",
        "\n",
        "### <b>Attribute Information: </b>\n",
        "\n",
        "* ### Date : year-month-day\n",
        "* ### Rented Bike count - Count of bikes rented at each hour\n",
        "* ### Hour - Hour of he day\n",
        "* ### Temperature-Temperature in Celsius\n",
        "* ### Humidity - %\n",
        "* ### Windspeed - m/s\n",
        "* ### Visibility - 10m\n",
        "* ### Dew point temperature - Celsius\n",
        "* ### Solar radiation - MJ/m2\n",
        "* ### Rainfall - mm\n",
        "* ### Snowfall - cm\n",
        "* ### Seasons - Winter, Spring, Summer, Autumn\n",
        "* ### Holiday - Holiday/No holiday\n",
        "* ### Functional Day - NoFunc(Non Functional Hours), Fun(Functional hours)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dByMsuzT8Tnw"
      },
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading and understanding the data"
      ],
      "metadata": {
        "id": "vb2ZGCH-byp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3Qx1CsS8Uhj",
        "outputId": "b1c71ff5-2bd7-4bb1-e997-baa4efb5c7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Datasets/SeoulBikeData.csv', encoding= 'unicode_escape',parse_dates=True)"
      ],
      "metadata": {
        "id": "JMQBS7C08eYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring the first five rows of the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ku8bpgtw8zgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring the last five rows of the dataset\n",
        "df.tail()"
      ],
      "metadata": {
        "id": "4292ecgI9Pye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspecting the length and number of columns of the dataset\n",
        "df.shape"
      ],
      "metadata": {
        "id": "jysRVNz-cV34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking null values and data types of each columns\n",
        "df.info()"
      ],
      "metadata": {
        "id": "HARwcvbu9UKD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b7d3813-0152-4573-9e55-5ce6080c1eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8760 entries, 0 to 8759\n",
            "Data columns (total 14 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   Date                       8760 non-null   object \n",
            " 1   Rented Bike Count          8760 non-null   int64  \n",
            " 2   Hour                       8760 non-null   int64  \n",
            " 3   Temperature(°C)            8760 non-null   float64\n",
            " 4   Humidity(%)                8760 non-null   int64  \n",
            " 5   Wind speed (m/s)           8760 non-null   float64\n",
            " 6   Visibility (10m)           8760 non-null   int64  \n",
            " 7   Dew point temperature(°C)  8760 non-null   float64\n",
            " 8   Solar Radiation (MJ/m2)    8760 non-null   float64\n",
            " 9   Rainfall(mm)               8760 non-null   float64\n",
            " 10  Snowfall (cm)              8760 non-null   float64\n",
            " 11  Seasons                    8760 non-null   object \n",
            " 12  Holiday                    8760 non-null   object \n",
            " 13  Functioning Day            8760 non-null   object \n",
            "dtypes: float64(6), int64(4), object(4)\n",
            "memory usage: 958.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# duplicate\n",
        "print(df[df.duplicated()].sum())"
      ],
      "metadata": {
        "id": "df-Dkj2o9W5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding statistical measures of numerical columns\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "5-FSEJB-90C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Extracting month and year from 'Date' column\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['year'] = pd.DatetimeIndex(df['Date']).year\n",
        "df['month'] = pd.DatetimeIndex(df['Date']).month"
      ],
      "metadata": {
        "id": "HLpIToAyHS46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the date column\n",
        "df.drop('Date',axis = 1,inplace = True)"
      ],
      "metadata": {
        "id": "E9cx7q-3HZeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checks the unique values of the newly formed columns\n",
        "df['year'].unique()"
      ],
      "metadata": {
        "id": "fqiO5G6bHi-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['month'].unique()"
      ],
      "metadata": {
        "id": "bBy6xqQDHkwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Replacing month numbers with month names\n",
        "\n",
        "df.replace({'month':{1: 'January',2: 'February',3:'March',4:'April',5:'May',6:'June',\n",
        "                     7:'July',8:'August',9:'September',10:'October',11:'November',12:'December'}},inplace=True)"
      ],
      "metadata": {
        "id": "ruQYlFUQHnS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Hour'].unique()"
      ],
      "metadata": {
        "id": "FhQYSu59aK4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "wzG5v_g_Htcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory data analysis"
      ],
      "metadata": {
        "id": "jZJPw5m19_cH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this step we are going to discover pattens and to check assumptions with the help of visualization.** "
      ],
      "metadata": {
        "id": "hpgYOZ7vc9Il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting names of numerical columns from the data\n",
        "numeric_features = df.describe().columns\n",
        "numeric_features"
      ],
      "metadata": {
        "id": "AJaJmBb8-E4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distplot and box plot of numeric features\n",
        "\n",
        "for var in numeric_features:\n",
        "    plt.figure(figsize=(12,6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    fig = sns.boxplot(y=df[var])\n",
        "    fig.set_title('')\n",
        "    fig.set_ylabel(var)\n",
        "    \n",
        "# Distplot  \n",
        "    plt.subplot(1, 2, 2)\n",
        "    fig = sns.distplot(df[var].dropna())\n",
        "    fig.set_ylabel('frequency')\n",
        "    fig.set_xlabel(var)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "a-d8656FRk2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The distribution of temperature, humidity and dew point temperature are nearly normal.**\n",
        "\n",
        "**The distribution of rented bike count and wind speed are slightly right skewed. Visibility column is severely left skewed.**\n",
        "\n",
        "**Columns like snowfall, rainfall and solar radiation contains most of the values as zero.**\n",
        "\n",
        "**There are less data for the year 2017.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Kr6zjTsUex1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Relation of numeric features with Rented Bike Count\n",
        "for col in numeric_features[1:]:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = df[col]\n",
        "    label = df['Rented Bike Count']\n",
        "    correlation = feature.corr(label)\n",
        "    plt.scatter(x=feature, y=label)\n",
        "    plt.xlabel(col)\n",
        "    plt.ylabel('Rented Bike Count')\n",
        "    ax.set_title('Rented Bike Count vs ' + col + '- correlation: ' + str(correlation))\n",
        "    z = np.polyfit(df[col], df['Rented Bike Count'], 1)\n",
        "    y_hat = np.poly1d(z)(df[col])\n",
        "\n",
        "    plt.plot(df[col], y_hat, \"r--\", lw=1)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xvO0pX5BAPlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Features like hour, temperature and dew point temperature are highly correlated with the dependent variable as compared to other variables.**\n",
        "\n",
        "**Humidity, snowfall and rainfall are negatively correlated with dependent variable with very low correlation coefficient.**\n",
        "\n",
        "**The peak time for bike renting is during the working hours that is from morning 7am to 10am and from evening 4pm to 9pm.**\n",
        "\n"
      ],
      "metadata": {
        "id": "X3fRVy1bjIn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Square root transform of dependent variable to make the distribution normal\n",
        "plt.figure(figsize=(7,7))\n",
        "sns.distplot(np.sqrt(df['Rented Bike Count']),color=\"r\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "beSP72vMBjv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting names of categorical columns from the data\n",
        "categorical_features = df.describe(include=['object','category']).columns\n",
        "categorical_features"
      ],
      "metadata": {
        "id": "8kc8DUCFCKGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bar plot of categorical features\n",
        "for col in categorical_features:\n",
        "    counts = df[col].value_counts().sort_index()\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    counts.plot.bar(ax = ax, color='steelblue')\n",
        "    ax.set_title(col + ' counts')\n",
        "    ax.set_xlabel(col) \n",
        "    ax.set_ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cp2X4kAwCWcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Box plot of categorical features with respect to dependent variable\n",
        "for col in categorical_features:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    df.boxplot(column = 'Rented Bike Count', by = col, ax = ax)\n",
        "    ax.set_title('Label by ' + col)\n",
        "    ax.set_ylabel(\"Rented Bike Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "erwz7zxwCfPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bike renting is less in winter season as compared to other seasons.**\n",
        "\n",
        "**In holidays bike renting is slightly less.**\n",
        "\n",
        "**There are very few peoples renting bikes in the month of December, January and february.**"
      ],
      "metadata": {
        "id": "zploZd71nmLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Correlation matrix\n",
        "plt.figure(figsize=(15,8))\n",
        "correlation = df.corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='coolwarm')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cWARKMJoCvHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Multicollinearity\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "def calc_vif(X):\n",
        "\n",
        "  # Calculating VIF\n",
        "  vif = pd.DataFrame()\n",
        "  vif[\"variables\"] = X.columns\n",
        "  vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "  return(vif)"
      ],
      "metadata": {
        "id": "tHUzgTfFC3A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_vif(df[[i for i in df.describe().columns if i not in ['Rented Bike Count']]])"
      ],
      "metadata": {
        "id": "BpOMEEq3C-F0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As year has high VIF value, including it in our model results in unstable parameter estimate.**"
      ],
      "metadata": {
        "id": "5Y6Y1s1Xpvy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VIF without year column\n",
        "calc_vif(df[[i for i in df.describe().columns if i not in ['Rented Bike Count','year']]])"
      ],
      "metadata": {
        "id": "HeGIgpSeLwEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "RijbxD1-q6Yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a list of columns\n",
        "x = list(df.describe().columns)"
      ],
      "metadata": {
        "id": "LPCCcEOjDR51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "sg6Zx1Y2KVnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeical features that will go to our model\n",
        "numerical_features = [i for i in x if i not in ['Rented Bike Count','year','Rainfall(mm)','Snowfall (cm)']]"
      ],
      "metadata": {
        "id": "_b2mLz9cDGl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As in snowfall and rainfall columns most of the values are zero and also correlation of them with the dependent variable is very less, we are not going to include them in our model building.**"
      ],
      "metadata": {
        "id": "leDdW12JiW4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a copy so that we can make changes in the data during encoding.\n",
        "df1 = df.copy()"
      ],
      "metadata": {
        "id": "f0YnoQ18DNrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting categorical features to numeric \n",
        "#label encoding\n",
        "encoders_nums = {\"Holiday\":{\"Holiday\":1,\"No Holiday\":0} ,\"Functioning Day\":{\"Yes\":1,\"No\":0}}\n",
        "df1= df1.replace(encoders_nums)"
      ],
      "metadata": {
        "id": "AUpmUQEHD0hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encoding\n",
        "df1 = pd.get_dummies(df1, columns=['Seasons','month'])"
      ],
      "metadata": {
        "id": "TdI6DZbREKNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "O4502UUmEPbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "I2TRBCZjEbeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Final feature list\n",
        "features = numerical_features.copy()\n",
        "features.extend(['Holiday','Functioning Day', 'Seasons_Autumn', 'Seasons_Spring', 'Seasons_Summer','Seasons_Winter',\n",
        "                'month_April', 'month_August','month_December', 'month_February', 'month_January', 'month_July',\n",
        "                 'month_June', 'month_March', 'month_May', 'month_November','month_October', 'month_September'])\n",
        "features"
      ],
      "metadata": {
        "id": "FJITSdO3EsXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(features)"
      ],
      "metadata": {
        "id": "vkiYP4BDNgVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**There are total 25 features and 1 dependent variable which we will use to fit our model.**"
      ],
      "metadata": {
        "id": "brAit_pbrJK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizing the features\n",
        "X = df1[features].apply(zscore)"
      ],
      "metadata": {
        "id": "-iutprxX28L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforming dependent variable using squareroot transformation.\n",
        "y = np.sqrt(df1['Rented Bike Count'])"
      ],
      "metadata": {
        "id": "NNcHezou33DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into two parts where the test data contains 20% of orignal data.\n",
        "X_train, X_test, y_train, y_test = train_test_split( X,y , test_size = 0.2, random_state = 5) "
      ],
      "metadata": {
        "id": "mPYLiJzu3l2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "qKsogvxBwBdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "yMMW5B4NwKrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "a51gjUsD3_4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model fitting**"
      ],
      "metadata": {
        "id": "ZYMxWKe94iiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an instance for linear regression \n",
        "reg = LinearRegression()\n",
        "# Model fitting\n",
        "reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "tQoL6N7R4EQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "y_train_pred = reg.predict(X_train)\n",
        "y_test_pred = reg.predict(X_test)"
      ],
      "metadata": {
        "id": "AzR9K6Ib4VtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model evaluation**"
      ],
      "metadata": {
        "id": "D4tFlcX94eny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean Squared Error and Root Mean Square Error for train data\n",
        "\n",
        "MSE_train  = mean_squared_error((y_train)**2,(y_train_pred)**2)\n",
        "print(\"Train MSE :\" , MSE_train)\n",
        "\n",
        "RMSE_train = np.sqrt(MSE_train)\n",
        "print(\"Train RMSE :\" ,RMSE_train)\n",
        "\n",
        "#Mean Square Error and Root Mean Square Error for test data\n",
        "\n",
        "MSE_test  = mean_squared_error((y_test)**2,(y_test_pred)**2)\n",
        "print(\"Test MSE :\" , MSE_test)\n",
        "\n",
        "RMSE_test = np.sqrt(MSE_test)\n",
        "print(\"Test RMSE :\" ,RMSE_test)"
      ],
      "metadata": {
        "id": "bE146CVY4a97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#r-square matrix for train and test datas\n",
        "r2_train = r2_score((y_train)**2, (y_train_pred)**2)\n",
        "r2_test = r2_score((y_test)**2, (y_test_pred)**2)\n",
        "print(\"train r2 score :\" , r2_train)\n",
        "print(\"test r2 score :\" , r2_test)"
      ],
      "metadata": {
        "id": "fQEWpm4g5SXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculation of adjusted r2\n",
        "print(\"Adjusted_Train_R2_linear : \",1-(1-r2_score((y_train)**2, (y_train_pred)**2))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))\n",
        "print(\"Adjusted_Test_R2_linear : \",1-(1-r2_score((y_test)**2, (y_test_pred)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "OT2ErWfUsQWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As the accuracy score is very low, the model has high bias. To decrease the bias next we will try to do polynomial regression.** "
      ],
      "metadata": {
        "id": "NTF0Tw2xG-Mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)"
      ],
      "metadata": {
        "id": "fCpb2ak7Sn0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coefficients = pd.concat([pd.DataFrame(X.columns),pd.DataFrame(np.transpose(reg.coef_))], axis = 1)"
      ],
      "metadata": {
        "id": "ATvAbZ1sP14D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef = coefficients.iloc[:,0]\n",
        "val = coefficients.iloc[:,1]"
      ],
      "metadata": {
        "id": "p-Z_E2XQVaUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the bar plot of feature importance\n",
        "fig_dims = (4,8)\n",
        "fig = plt.subplots(figsize=fig_dims)\n",
        "plt.barh(coef, val, color ='maroon')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TwGBlJCTWasA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Functioning day,hour and dew point temperature are affecting positively rented bike count the most.**\n",
        "\n",
        "**Humidity negatively impacting most the dependent variable.**  "
      ],
      "metadata": {
        "id": "G7z5nivhQwIr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Polynomial regression"
      ],
      "metadata": {
        "id": "B2FVQbP6CEbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmses = []\n",
        "degrees = np.arange(1,5)\n",
        "min_rmse, min_deg = 1e10, 0\n",
        "\n",
        "for deg in degrees:\n",
        "\n",
        "    # Train features\n",
        "    poly_features = PolynomialFeatures(degree=deg, include_bias=True)\n",
        "    X_poly_train = poly_features.fit_transform(X_train)\n",
        "\n",
        "    # Linear regression\n",
        "    poly_reg = LinearRegression()\n",
        "    poly_reg.fit(X_poly_train, y_train)\n",
        "\n",
        "    # Compare with test data\n",
        "    X_poly_test = poly_features.fit_transform(X_test)\n",
        "    poly_predict = poly_reg.predict(X_poly_test)\n",
        "    poly_mse = mean_squared_error(y_test, poly_predict)\n",
        "    poly_rmse = np.sqrt(poly_mse)\n",
        "    rmses.append(poly_rmse)\n",
        "    \n",
        "    # Cross-validation of degree\n",
        "    if min_rmse > poly_rmse:\n",
        "        min_rmse = poly_rmse\n",
        "        min_deg = deg\n",
        "\n",
        "# Plot and present results\n",
        "print('Best degree {} with RMSE {}'.format(min_deg, min_rmse))\n",
        "        \n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "ax.plot(degrees, rmses)\n",
        "ax.set_yscale('log')\n",
        "ax.set_xlabel('Degree')\n",
        "ax.set_ylabel('RMSE')"
      ],
      "metadata": {
        "id": "cQtAXLFA_BL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From the above plot, it is clear that best degree for polynomial regression is 3 for which RMSE = 5.12**"
      ],
      "metadata": {
        "id": "3WZS6-vMIpzi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model fitting**"
      ],
      "metadata": {
        "id": "8q8cfz0z8GKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting three degree polynomial regression model \n",
        "poly = PolynomialFeatures(degree=3,include_bias=True)\n",
        "X_train_trans = poly.fit_transform(X_train)\n",
        "X_test_trans = poly.fit_transform(X_test)\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_trans, y_train)"
      ],
      "metadata": {
        "id": "BY-mu8FZMRua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model evaluation**"
      ],
      "metadata": {
        "id": "X150hcGR8K0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# r2 score calculation\n",
        "y_pred_train = lr.predict(X_train_trans)\n",
        "print(\"Train r2 score:\", r2_score((y_train)**2, (y_pred_train)**2))\n",
        "y_pred_test = lr.predict(X_test_trans)\n",
        "print(\"Test r2 score:\",r2_score((y_test)**2, (y_pred_test)**2))"
      ],
      "metadata": {
        "id": "bzVLuLiIMd_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculation of adjusted r2\n",
        "print(\"Adjusted_Train_R2_nonlinear : \",1-(1-r2_score((y_train)**2, (y_pred_train)**2))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))\n",
        "print(\"Adjusted_Test_R2_nonlinear : \",1-(1-r2_score((y_test)**2, (y_pred_test)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "rNc24oglHgFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MSE and RMSE for train data\n",
        "MSE_tr = mean_squared_error((y_train)**2, (y_pred_train)**2)\n",
        "print(\"Train MSE :\" , MSE_tr)\n",
        "print(\"Train RMSE :\" , np.sqrt(MSE_tr))"
      ],
      "metadata": {
        "id": "gNj8m3jWMvBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MSE and RMSE for test data\n",
        "MSE_te = mean_squared_error((y_test)**2, (y_pred_test)**2)\n",
        "print(\"Test MSE :\" , MSE_te)\n",
        "print(\"Test RMSE :\" , np.sqrt(MSE_te))"
      ],
      "metadata": {
        "id": "5UDg3Nm9MkqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**At degree 3, the model is overfitting the data. We will now apply some regularization techniques to decrease the variance.**"
      ],
      "metadata": {
        "id": "_pOG4JP-Sc62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ridge"
      ],
      "metadata": {
        "id": "TE6kgDO1S-1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing gridsearchcv on ridge regressor\n",
        "ridge = Ridge()\n",
        "parameters = {'alpha': [1e-3,1e-2,1e-1,1,5,10,20,30,100,.0014]}\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_regressor.fit(X_train_trans,y_train)"
      ],
      "metadata": {
        "id": "lg1mqHSRSdnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best parameter from gridsearchcv\n",
        "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
        "print(\"\\nUsing \",ridge_regressor.best_params_, \" the negative mean squared error is: \", ridge_regressor.best_score_)"
      ],
      "metadata": {
        "id": "b0bkYg96TW5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on train and test data\n",
        "y_pred_train_ridge = ridge_regressor.predict(X_train_trans)\n",
        "y_pred_test_ridge = ridge_regressor.predict(X_test_trans)"
      ],
      "metadata": {
        "id": "dRkyOAibTaxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculation of MSE \n",
        "MSE_train_ridge  = mean_squared_error((y_train)**2, (y_pred_train_ridge)**2)\n",
        "print(\"Train_MSE_ridge :\" , MSE_train_ridge)\n",
        "MSE_test_ridge  = mean_squared_error((y_test)**2, (y_pred_test_ridge)**2)\n",
        "print(\"Test_MSE_ridge :\" , MSE_test_ridge)\n",
        "\n",
        "\n",
        "#Calculation of RMSE\n",
        "RMSE_train_ridge = np.sqrt(MSE_train_ridge)\n",
        "print(\"Train_RMSE_ridge :\" ,RMSE_train_ridge)\n",
        "RMSE_test_ridge = np.sqrt(MSE_test_ridge)\n",
        "print(\"Test_RMSE_ridge :\" ,RMSE_test_ridge)"
      ],
      "metadata": {
        "id": "ftCvr2H3HpMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculation of r2 score\n",
        "r2_train_ridge = r2_score((y_train)**2, (y_pred_train_ridge)**2)\n",
        "r2_test_ridge = r2_score((y_test)**2, (y_pred_test_ridge)**2)\n",
        "print(\"r2_train_ridge :\" ,r2_train_ridge)\n",
        "print(\"r2_test_ridge :\" ,r2_test_ridge)"
      ],
      "metadata": {
        "id": "piLOvXqTTkvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculation of adjusted r2\n",
        "print(\"Adjusted_Train_R2_ridge : \",1-(1-r2_score((y_train)**2, (y_pred_train_ridge)**2))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))\n",
        "print(\"Adjusted_Test_R2_ridge : \",1-(1-r2_score((y_test)**2, (y_pred_test_ridge)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "hFhG9pfgTyQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lasso"
      ],
      "metadata": {
        "id": "6RgCuU76UKsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing gridsearchcv on lasso regressor\n",
        "lasso = Lasso()\n",
        "parameters = {'alpha': [1e-3,1e-2,1e-1,1,5,10,20,30,100,.0014]}\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "lasso_regressor.fit(X_train_trans, y_train)"
      ],
      "metadata": {
        "id": "TPC8ods6UQPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best parameter from gridsearchcv\n",
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"\\nUsing \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)"
      ],
      "metadata": {
        "id": "yRlqLXF8UWrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred_lasso_test = lasso_regressor.predict(X_test_trans)\n",
        "y_pred_lasso_train = lasso_regressor.predict(X_train_trans)"
      ],
      "metadata": {
        "id": "xo5j-nfuUYEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculation of MSE \n",
        "MSE_train_lasso  = mean_squared_error((y_train)**2, (y_pred_lasso_train)**2)\n",
        "print(\"Train_MSE_lasso :\" , MSE_train_lasso)\n",
        "MSE_test_lasso  = mean_squared_error((y_test)**2, (y_pred_lasso_test)**2)\n",
        "print(\"Test_MSE_lasso :\" , MSE_test_lasso)\n",
        "\n",
        "\n",
        "#Calculation of RMSE\n",
        "RMSE_train_lasso = np.sqrt(MSE_train_lasso)\n",
        "print(\"Train_RMSE_lasso :\" ,RMSE_train_lasso)\n",
        "RMSE_test_lasso = np.sqrt(MSE_test_lasso)\n",
        "print(\"Test_RMSE_lasso :\" ,RMSE_test_lasso)"
      ],
      "metadata": {
        "id": "qxP4HksXGT6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculation of r2 score\n",
        "r2_train_lasso = r2_score((y_train)**2, (y_pred_lasso_train)**2)\n",
        "r2_test_lasso = r2_score((y_test)**2, (y_pred_lasso_test)**2)\n",
        "print(\"r2_train_lasso :\" ,r2_train_lasso)\n",
        "print(\"r2_test_lasso :\" ,r2_test_lasso)"
      ],
      "metadata": {
        "id": "WrDL_ON4UsGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculation of adjusted r2\n",
        "print(\"Adjusted_Train_R2_lasso : \",1-(1-r2_score((y_train)**2, (y_pred_lasso_train)**2))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))\n",
        "print(\"Adjusted_Test_R2_lasso : \",1-(1-r2_score((y_test)**2, (y_pred_lasso_test)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "xJDgCwstXQKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ElasticNet"
      ],
      "metadata": {
        "id": "Ih9ZzuHBdkAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Performing gridsearchcv on elesticnet regression\n",
        "elastic = ElasticNet()\n",
        "parameters = {'alpha': [1e-3,1e-2,1e-1,1,5,10,20,30,100,.0014],\n",
        "              'l1_ratio':[0.3,0.4,0.5,0.6,0.7,0.8]}\n",
        "elastic_regressor = GridSearchCV(elastic, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "elastic_regressor.fit(X_train_trans, y_train)"
      ],
      "metadata": {
        "id": "3DR2UU_VdRVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Best parameter from gridsearchcv\n",
        "print(\"The best fit parameters are found out to be :\" ,elastic_regressor.best_params_)\n",
        "print(\"\\nUsing \",elastic_regressor.best_params_, \" the negative mean squared error is: \", elastic_regressor.best_score_)"
      ],
      "metadata": {
        "id": "0l_Rcq53Mllt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "y_pred_elasticnet_test = elastic_regressor.predict(X_test_trans)\n",
        "y_pred_elasticnet_train = elastic_regressor.predict(X_train_trans)"
      ],
      "metadata": {
        "id": "2pomRAdnMl8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculation of MSE \n",
        "MSE_train_elasticnet  = mean_squared_error((y_train)**2, (y_pred_elasticnet_train)**2)\n",
        "print(\"Train_MSE_elasticnet :\" , MSE_train_elasticnet)\n",
        "MSE_test_elasticnet  = mean_squared_error((y_test)**2, (y_pred_elasticnet_test)**2)\n",
        "print(\"Test_MSE_elasticnet :\" , MSE_test_elasticnet)\n",
        "\n",
        "\n",
        "#Calculation of RMSE\n",
        "RMSE_train_elasticnet = np.sqrt(MSE_train_elasticnet)\n",
        "print(\"Train_RMSE_elasticnet :\" ,RMSE_train_elasticnet)\n",
        "RMSE_test_elasticnet = np.sqrt(MSE_test_elasticnet)\n",
        "print(\"Test_RMSE_elasticnet :\" ,RMSE_test_elasticnet)"
      ],
      "metadata": {
        "id": "YnZYlaNxIyjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# r2 score calculation\n",
        "r2_train_elasticnet = r2_score((y_train)**2, (y_pred_elasticnet_train)**2)\n",
        "r2_test_elasticnet = r2_score((y_test)**2, (y_pred_elasticnet_test)**2)\n",
        "print(\"r2_train_elasticnet :\" ,r2_train_elasticnet)\n",
        "print(\"r2_test_elasticnet :\" ,r2_test_elasticnet)"
      ],
      "metadata": {
        "id": "GGjEJYgFM_QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adjusted r2 score calculation\n",
        "print(\"Adjusted_Train_R2_elasticnet : \",1-(1-r2_score((y_train)**2, (y_pred_elasticnet_train)**2))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))\n",
        "print(\"Adjusted_Test_R2_elasticnet : \",1-(1-r2_score((y_test)**2, (y_pred_elasticnet_test)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "Lg9I9VxuNYs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision tree"
      ],
      "metadata": {
        "id": "4ewhutXwbTNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an instance for decision tree regressor\n",
        "dt_model = DecisionTreeRegressor()"
      ],
      "metadata": {
        "id": "wm9Q_QnOmf9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining parameter list to perform GridSearchCV\n",
        "param_dict = {\"criterion\": [\"mse\", \"mae\"],\n",
        "              \"min_samples_split\": [10, 20, 40],\n",
        "              \"max_depth\": [2, 6, 8],\n",
        "              \"min_samples_leaf\": [20, 40, 100],\n",
        "              \"max_leaf_nodes\": [5, 20, 100],\n",
        "              }\n",
        "# GridSearchCV\n",
        "dt_grid = GridSearchCV(estimator=dt_model,param_grid = param_dict, cv=5)\n",
        "\n",
        "dt_grid.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "y9mCaP7ybYj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting best estimator from GridSearch\n",
        "dt_grid.best_estimator_"
      ],
      "metadata": {
        "id": "kAn4mUE7nTF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on train and test data\n",
        "\n",
        "dt_train_preds = dt_grid.predict(X_train)\n",
        "dt_test_preds = dt_grid.predict(X_test)"
      ],
      "metadata": {
        "id": "L3KKcjXCnmI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculation of MSE \n",
        "MSE_train_dt  = mean_squared_error((y_train)**2, (dt_train_preds)**2)\n",
        "print(\"Train_MSE_dt :\" , MSE_train_dt)\n",
        "MSE_test_dt  = mean_squared_error((y_test)**2, (dt_test_preds)**2)\n",
        "print(\"Test_MSE_dt :\" , MSE_test_dt)\n",
        "\n",
        "\n",
        "#Calculation of RMSE\n",
        "RMSE_train_dt = np.sqrt(MSE_train_dt)\n",
        "print(\"Train_RMSE_dt :\" ,RMSE_train_dt)\n",
        "RMSE_test_dt = np.sqrt(MSE_test_dt)\n",
        "print(\"Test_RMSE_dt :\" ,RMSE_test_dt)"
      ],
      "metadata": {
        "id": "DvrUD6AOJbFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#r-square matrix for train and test datas\n",
        "r2_train_dt = r2_score((y_train)**2, (dt_train_preds)**2)\n",
        "r2_test_dt = r2_score((y_test)**2, (dt_test_preds)**2)\n",
        "print(\"train r2 score dt :\" , r2_train_dt)\n",
        "print(\"test r2 score dt :\" , r2_test_dt)"
      ],
      "metadata": {
        "id": "I99AopgSnvij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculation of adjusted r2\n",
        "print(\"Adjusted_Train_R2_dt : \",1-(1-r2_score((y_train)**2, (dt_train_preds)**2))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))\n",
        "print(\"Adjusted_Test_R2_dt : \",1-(1-r2_score((y_test)**2, (dt_test_preds)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "xTJDNjKrFcn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = X_train.columns\n",
        "importances = dt_grid.best_estimator_.feature_importances_\n",
        "indices = np.argsort(importances)"
      ],
      "metadata": {
        "id": "v4CQXSmMEUZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting feature importance\n",
        "fig_dims = (4,8)\n",
        "fig = plt.subplots(figsize=fig_dims)\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(len(indices)), importances[indices], color='red', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GqyvH5ReEOL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random forest"
      ],
      "metadata": {
        "id": "TmLrVQtjccCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Grid\n",
        "param_dict = { \"n_estimators\"      : [10,30,100,200],\n",
        "               \"min_samples_split\" : [2,4,8],\n",
        "               \"max_depth\"         : [5,10,20,30]\n",
        "             }"
      ],
      "metadata": {
        "id": "fLkjFyXpciUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an instance of the RandomForestRegressor\n",
        "rf_model = RandomForestRegressor()\n",
        "\n",
        "# Grid search\n",
        "rf_grid = GridSearchCV(estimator=rf_model,\n",
        "                       param_grid = param_dict,\n",
        "                       cv = 3)\n",
        "\n",
        "rf_grid.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "6shy_8D3dPCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting best estimator from GridSearch\n",
        "rf_grid.best_estimator_"
      ],
      "metadata": {
        "id": "nYxgE7Mmgtut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on train and test data\n",
        "\n",
        "rf_train_preds = rf_grid.predict(X_train)\n",
        "rf_test_preds = rf_grid.predict(X_test)"
      ],
      "metadata": {
        "id": "65-0Sg9ghFtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculation of MSE \n",
        "MSE_train_rf  = mean_squared_error((y_train)**2, (rf_train_preds)**2)\n",
        "print(\"Train_MSE_rf :\" , MSE_train_rf)\n",
        "MSE_test_rf  = mean_squared_error((y_test)**2, (rf_test_preds)**2)\n",
        "print(\"Test_MSE_rf :\" , MSE_test_rf)\n",
        "\n",
        "\n",
        "#Calculation of RMSE\n",
        "RMSE_train_rf = np.sqrt(MSE_train_rf)\n",
        "print(\"Train_RMSE_rf :\" ,RMSE_train_rf)\n",
        "RMSE_test_rf = np.sqrt(MSE_test_rf)\n",
        "print(\"Test_RMSE_rf :\" ,RMSE_test_rf)"
      ],
      "metadata": {
        "id": "ukjf84-7J8vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#r-square matrix for train and test datas\n",
        "r2_train_rf = r2_score((y_train)**2, (rf_train_preds)**2)\n",
        "r2_test_rf = r2_score((y_test)**2, (rf_test_preds)**2)\n",
        "print(\"train r2 score rf :\" , r2_train_rf)\n",
        "print(\"test r2 score rf :\" , r2_test_rf)"
      ],
      "metadata": {
        "id": "pAXyPFtohSOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculation of adjusted r2\n",
        "print(\"Adjusted_Train_R2_rf : \",1-(1-r2_score((y_train)**2, (rf_train_preds)**2))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))\n",
        "print(\"Adjusted_Test_R2_rf : \",1-(1-r2_score((y_test)**2, (rf_test_preds)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "udQvk9snFp9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = X_train.columns\n",
        "importances = rf_grid.best_estimator_.feature_importances_\n",
        "indices = np.argsort(importances)"
      ],
      "metadata": {
        "id": "WcxpEDxmB62k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting feature importance\n",
        "fig_dims = (4,8)\n",
        "fig = plt.subplots(figsize=fig_dims)\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(len(indices)), importances[indices], color='red', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A6GFzft8Cpxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient boosting"
      ],
      "metadata": {
        "id": "JE4VbNhdjEOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining parameter list for GridSearch\n",
        "param_dict= {'learning_rate' : [0.01,0.02,0.03,0.04],\n",
        "              'subsample'    : [0.9, 0.5, 0.2, 0.1],\n",
        "              'n_estimators' : [100,300,500],\n",
        "              'max_depth'    : [4,6,8,10]\n",
        "            }"
      ],
      "metadata": {
        "id": "WdNa2_ETjLtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the RandomForestClassifier\n",
        "gb_model = GradientBoostingRegressor()\n",
        "\n",
        "# Grid search\n",
        "gb_grid = GridSearchCV(estimator=gb_model,\n",
        "                       param_grid = param_dict,\n",
        "                       cv = 2, n_jobs=-1)\n",
        "\n",
        "gb_grid.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "s5LSPXYgjjKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting best estimator from GridSearchCV\n",
        "gb_grid.best_estimator_"
      ],
      "metadata": {
        "id": "iaVQ3dJ4k0ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on train and test data\n",
        "\n",
        "gb_train_preds = gb_grid.predict(X_train)\n",
        "gb_test_preds = gb_grid.predict(X_test)"
      ],
      "metadata": {
        "id": "Kvi-mtxyk5P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculation of MSE \n",
        "MSE_train_gb  = mean_squared_error((y_train)**2, (gb_train_preds)**2)\n",
        "print(\"Train_MSE_gb :\" , MSE_train_gb)\n",
        "MSE_test_gb  = mean_squared_error((y_test)**2, (gb_test_preds)**2)\n",
        "print(\"Test_MSE_gb :\" , MSE_test_gb)\n",
        "\n",
        "\n",
        "#Calculation of RMSE\n",
        "RMSE_train_gb = np.sqrt(MSE_train_gb)\n",
        "print(\"Train_RMSE_gb :\" ,RMSE_train_gb)\n",
        "RMSE_test_gb = np.sqrt(MSE_test_gb)\n",
        "print(\"Test_RMSE_gb :\" ,RMSE_test_gb)"
      ],
      "metadata": {
        "id": "y83HoUlVKVGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#r-square matrix for train and test datas\n",
        "r2_train_gb = r2_score((y_train)**2, (gb_train_preds)**2)\n",
        "r2_test_gb = r2_score((y_test)**2, (gb_test_preds)**2)\n",
        "print(\"train r2 score gb :\" , r2_train_gb)\n",
        "print(\"test r2 score gb :\" , r2_test_gb)"
      ],
      "metadata": {
        "id": "TjNcORTYlHTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculation of adjusted r2\n",
        "print(\"Adjusted_Train_R2_gb : \",1-(1-r2_score((y_train)**2, (gb_train_preds)**2))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))\n",
        "print(\"Adjusted_Test_R2_gb : \",1-(1-r2_score((y_test)**2, (gb_test_preds)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "QXCIuaXtF5Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = X_train.columns\n",
        "importances = gb_grid.best_estimator_.feature_importances_\n",
        "indices = np.argsort(importances)"
      ],
      "metadata": {
        "id": "RuibbIcADF4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting feature importance\n",
        "fig_dims = (4,8)\n",
        "fig = plt.subplots(figsize=fig_dims)\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(len(indices)), importances[indices], color='red', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-W_34kw3DLeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGboost"
      ],
      "metadata": {
        "id": "dD50kmcIAmhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining parameter list for GridSearch\n",
        "param_dict = { 'max_depth': [3,6,10],\n",
        "           'learning_rate': [0.01, 0.05, 0.1],\n",
        "           'n_estimators': [100, 500, 1000],\n",
        "           'colsample_bytree': [0.3, 0.7]}"
      ],
      "metadata": {
        "id": "nmXk7JnyBIZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an instance for XGBoost Regressor\n",
        "xgb_model = xgb.XGBRegressor(seed = 20)"
      ],
      "metadata": {
        "id": "jSeaKKFXBQXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid search\n",
        "xgb_grid = GridSearchCV(estimator=xgb_model, \n",
        "                   param_grid=param_dict,\n",
        "                   scoring='neg_mean_squared_error',cv=3, \n",
        "                   verbose=1)\n",
        "xgb_grid.fit(X_train,y_train)\n"
      ],
      "metadata": {
        "id": "ninT8cq8Bg7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting best estimator from GridSearchCV\n",
        "xgb_grid.best_estimator_"
      ],
      "metadata": {
        "id": "X9OrwMvxDvaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions on train and test data\n",
        "\n",
        "xgb_train_preds = xgb_grid.predict(X_train)\n",
        "xgb_test_preds = xgb_grid.predict(X_test)"
      ],
      "metadata": {
        "id": "Oy0mOXBJD4Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculation of MSE \n",
        "MSE_train_xgb  = mean_squared_error((y_train)**2, (xgb_train_preds)**2)\n",
        "print(\"Train_MSE_xgb :\" , MSE_train_xgb)\n",
        "MSE_test_xgb  = mean_squared_error((y_test)**2, (xgb_test_preds)**2)\n",
        "print(\"Test_MSE_xgb :\" , MSE_test_xgb)\n",
        "\n",
        "\n",
        "#Calculation of RMSE\n",
        "RMSE_train_xgb = np.sqrt(MSE_train_xgb)\n",
        "print(\"Train_RMSE_xgb :\" ,RMSE_train_xgb)\n",
        "RMSE_test_xgb = np.sqrt(MSE_test_xgb)\n",
        "print(\"Test_RMSE_xgb :\" ,RMSE_test_xgb)"
      ],
      "metadata": {
        "id": "7EFhXr0QKonK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#r-square matrix for train and test datas\n",
        "r2_train_xgb = r2_score((y_train)**2, (xgb_train_preds)**2)\n",
        "r2_test_xgb = r2_score((y_test)**2, (xgb_test_preds)**2)\n",
        "print(\"train r2 score xgb :\" , r2_train_xgb)\n",
        "print(\"test r2 score xgb :\" , r2_test_xgb)"
      ],
      "metadata": {
        "id": "mfMQptDNEDko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculation of adjusted r2\n",
        "print(\"Adjusted_Train_R2_xgb : \",1-(1-r2_score((y_train)**2, (xgb_train_preds)**2))*((X_train.shape[0]-1)/(X_train.shape[0]-X_train.shape[1]-1)))\n",
        "print(\"Adjusted_Test_R2_xgb : \",1-(1-r2_score((y_test)**2, (xgb_test_preds)**2))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1)))"
      ],
      "metadata": {
        "id": "gnd_5fkKGChy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = X_train.columns\n",
        "importances = xgb_grid.best_estimator_.feature_importances_\n",
        "indices = np.argsort(importances)"
      ],
      "metadata": {
        "id": "noOenTh1Dtr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting feature importance\n",
        "fig_dims = (4,8)\n",
        "fig = plt.subplots(figsize=fig_dims)\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(len(indices)), importances[indices], color='red', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1BQnF9ERD6f6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "YSUGn1v7uhaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* With accuracy of 58% linear regression model has high bias.\n",
        "\n",
        "* Non linear regression model(degree 3) with regularization gives good accuracy score of 83% on training data and 81% on testing data.\n",
        "\n",
        "* Decision tree model gives accuracy score of 81% on training data whereas 78% accuracy on testing data.\n",
        "\n",
        "* All the 3 different ensemble methods are overfitting the data with almost 10% difference between train and test accuracy.\n",
        "\n",
        "* Out of all ensemble methods used gradient boosting and XGBoost giving slightly good result with training accuracy of 98% and testing accuracy of 88%.\n",
        "\n",
        "* Temperature, hour and humidity are the three most important features given by all the models except XGBoost."
      ],
      "metadata": {
        "id": "dcK9zkzNHMOe"
      }
    }
  ]
}